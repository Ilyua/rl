{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dff80d3-fdfb-4f9f-bffe-1a2a2e6c9841",
   "metadata": {},
   "source": [
    "# RL and Advanced DL: Домашнее задание 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b574284-8495-4105-a0ae-ad43373a0678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bcbb6fc-2df2-4a63-9f7c-75d0dc4d7a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as st\n",
    "import scipy.integrate as integrate\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn import linear_model\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import statsmodels.api as sm\n",
    "from matplotlib.colors import LogNorm\n",
    "import pickle\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "\n",
    "import cProfile\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.autograd import Variable\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "palette = sns.color_palette()\n",
    "figsize = (15,8)\n",
    "legend_fontsize = 16\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif'})\n",
    "rc('text', usetex=True)\n",
    "rc('text.latex',preamble=r'\\usepackage[utf8]{inputenc}')\n",
    "rc('text.latex',preamble=r'\\usepackage[russian]{babel}')\n",
    "rc('figure', **{'dpi': 300})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6143170-a494-425b-9a9c-a93d62b456f8",
   "metadata": {},
   "source": [
    "## Классы для крестиков ноликов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c6c1016-1d1e-4f05-847b-361b26d84c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ROWS, N_COLS, N_WIN = 3, 3, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc2cad80-203e-40af-b0c3-2d2dbbf13601",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe(gym.Env):\n",
    "    def __init__(self, n_rows=N_ROWS, n_cols=N_COLS, n_win=N_WIN, clone=None):\n",
    "        if clone is not None:\n",
    "            self.n_rows, self.n_cols, self.n_win = clone.n_rows, clone.n_cols, clone.n_win\n",
    "            self.board = copy.deepcopy(clone.board)\n",
    "            self.curTurn = clone.curTurn\n",
    "            self.emptySpaces = None\n",
    "            self.boardHash = None\n",
    "        else:\n",
    "            self.n_rows = n_rows\n",
    "            self.n_cols = n_cols\n",
    "            self.n_win = n_win\n",
    "\n",
    "            self.reset()\n",
    "\n",
    "    def getEmptySpaces(self):\n",
    "        if self.emptySpaces is None:\n",
    "            res = np.where(self.board == 0)\n",
    "            self.emptySpaces = np.array([ (i, j) for i,j in zip(res[0], res[1]) ])\n",
    "        return self.emptySpaces\n",
    "\n",
    "    def makeMove(self, player, i, j):\n",
    "        self.board[i, j] = player\n",
    "        self.emptySpaces = None\n",
    "        self.boardHash = None\n",
    "\n",
    "    def getHash(self):\n",
    "        if self.boardHash is None:\n",
    "            self.boardHash = ''.join(['%s' % (x+1) for x in self.board.reshape(self.n_rows * self.n_cols)])\n",
    "        return self.boardHash\n",
    "\n",
    "    def isTerminal(self):\n",
    "        # проверим, не закончилась ли игра\n",
    "        cur_marks, cur_p = np.where(self.board == self.curTurn), self.curTurn\n",
    "        for i,j in zip(cur_marks[0], cur_marks[1]):\n",
    "            win = False\n",
    "            if i <= self.n_rows - self.n_win:\n",
    "                if np.all(self.board[i:i+self.n_win, j] == cur_p):\n",
    "                    win = True\n",
    "            if not win:\n",
    "                if j <= self.n_cols - self.n_win:\n",
    "                    if np.all(self.board[i,j:j+self.n_win] == cur_p):\n",
    "                        win = True\n",
    "            if not win:\n",
    "                if i <= self.n_rows - self.n_win and j <= self.n_cols - self.n_win:\n",
    "                    if np.all(np.array([ self.board[i+k,j+k] == cur_p for k in range(self.n_win) ])):\n",
    "                        win = True\n",
    "            if not win:\n",
    "                if i <= self.n_rows - self.n_win and j >= self.n_win-1:\n",
    "                    if np.all(np.array([ self.board[i+k,j-k] == cur_p for k in range(self.n_win) ])):\n",
    "                        win = True\n",
    "            if win:\n",
    "                self.gameOver = True\n",
    "                return self.curTurn\n",
    "\n",
    "        if len(self.getEmptySpaces()) == 0:\n",
    "            self.gameOver = True\n",
    "            return 0\n",
    "\n",
    "        self.gameOver = False\n",
    "        return None\n",
    "\n",
    "    def printBoard(self):\n",
    "        for i in range(0, self.n_rows):\n",
    "            print('----'*(self.n_cols)+'-')\n",
    "            out = '| '\n",
    "            for j in range(0, self.n_cols):\n",
    "                if self.board[i, j] == 1:\n",
    "                    token = 'x'\n",
    "                if self.board[i, j] == -1:\n",
    "                    token = 'o'\n",
    "                if self.board[i, j] == 0:\n",
    "                    token = ' '\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('----'*(self.n_cols)+'-')\n",
    "\n",
    "    def getState(self):\n",
    "        return (self.getHash(), self.getEmptySpaces(), self.curTurn)\n",
    "\n",
    "    def action_from_int(self, action_int):\n",
    "        return ( int(action_int / self.n_cols), int(action_int % self.n_cols))\n",
    "\n",
    "    def int_from_action(self, action):\n",
    "        return action[0] * self.n_cols + action[1]\n",
    "    \n",
    "    def step(self, action):\n",
    "        if self.board[action[0], action[1]] != 0:\n",
    "            return self.getState(), -10, True, {}\n",
    "        self.makeMove(self.curTurn, action[0], action[1])\n",
    "        reward = self.isTerminal()\n",
    "        self.curTurn = -self.curTurn\n",
    "        return self.getState(), 0 if reward is None else reward, reward is not None, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((self.n_rows, self.n_cols), dtype=int)\n",
    "        self.boardHash = None\n",
    "        self.gameOver = False\n",
    "        self.emptySpaces = None\n",
    "        self.curTurn = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e318d85c-6efc-473d-b5e5-09d96b2b079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_board(env, pi, showtext=True, verbose=True, fontq=20, fontx=60):\n",
    "    '''Рисуем доску с оценками из стратегии pi'''\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    X, Y = np.meshgrid(np.arange(0, env.n_rows), np.arange(0, env.n_rows))\n",
    "    Z = np.zeros((env.n_rows, env.n_cols)) + .01\n",
    "    s, actions = env.getHash(), env.getEmptySpaces()\n",
    "    if pi is not None and s in pi.Q:\n",
    "        for i, a in enumerate(actions):\n",
    "            Z[a[0], a[1]] = pi.Q[s][i]\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    surf = ax.imshow(Z, cmap=plt.get_cmap('Accent', 10), vmin=-1, vmax=1)\n",
    "    if showtext:\n",
    "        for i,a in enumerate(actions):\n",
    "            if pi is not None and s in pi.Q:\n",
    "                ax.text( a[1] , a[0] , \"%.3f\" % pi.Q[s][i], fontsize=fontq, horizontalalignment='center', verticalalignment='center', color=\"w\" )\n",
    "    for i in range(env.n_rows):\n",
    "        for j in range(env.n_cols):\n",
    "            if env.board[i, j] == -1:\n",
    "                ax.text(j, i, \"O\", fontsize=fontx, horizontalalignment='center', verticalalignment='center', color=\"w\" )\n",
    "            if env.board[i, j] == 1:\n",
    "                ax.text(j, i, \"X\", fontsize=fontx, horizontalalignment='center', verticalalignment='center', color=\"w\" )\n",
    "#     cbar = plt.colorbar(surf, ticks=[0, 1])\n",
    "    ax.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "def get_and_print_move(env, pi, s, actions, random=False, verbose=True, fontq=20, fontx=60):\n",
    "    '''Делаем ход, рисуем доску'''\n",
    "    plot_board(env, pi, fontq=fontq, fontx=fontx)\n",
    "    if verbose and (pi is not None):\n",
    "        if s in pi.Q:\n",
    "            for i,a in enumerate(actions):\n",
    "                print(i, a, pi.Q[s][i])\n",
    "        else:\n",
    "            print(\"Стратегия не знает, что делать...\")\n",
    "    if random:\n",
    "        return np.random.randint(len(actions))\n",
    "    else:\n",
    "        return pi.getActionGreedy(s, len(actions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60cab69-cc35-476f-9803-1d1b061604c9",
   "metadata": {},
   "source": [
    "\n",
    "# Табличный Q-learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a113379-663b-4c3e-8738-7458c6a44989",
   "metadata": {},
   "source": [
    "## Идея: сделаем два агента, которые будут играть друг против друга по своим табличным функциям \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "968a0782-819f-4b71-9b37-7cd07f5a45da",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TicTacToe(n_rows=3, n_cols=3, n_win=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8b1dc91a-eac0-4a8c-86fe-0ea1e3c2d12d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "814ea356-c546-403f-bec6-625471a9f62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SexyEnvironment():\n",
    "    def __init__(self,base_env):\n",
    "        \n",
    "        self.env = base_env\n",
    "        self.env.reset()\n",
    "        \n",
    "        self.action_space_dim = len(self.env.getState()[1])\n",
    "        self.state_space_dim = 3**(len(self.env.getState()[0]))\n",
    "        \n",
    "    def reset(self):\n",
    "        self.env.reset()\n",
    "        return self.env.getState()[0]\n",
    "    \n",
    "    def step(self,action):\n",
    "        env_output = self.env.step(self.env.action_from_int(action))\n",
    "        state= env_output[0][0]\n",
    "        reward = env_output[1]\n",
    "        terminated = env_output[2]\n",
    "        \n",
    "        return state,reward,terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0e7e2d20-a525-4b0c-83d9-e8f7c5c13e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableQlearning():\n",
    "    def __init__(action_space_dim,state_space_dim,env,alpha=0.01,gamma=0.3):\n",
    "        self.Q = np.randn((state_space_dim,action_space_dim))\n",
    "        self.max_learning_iterations = 10_000\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.env = env\n",
    "        self.epsilon = 0.1\n",
    "        \n",
    "        self.counter = 1\n",
    "        sef.Q_prev = None\n",
    "        \n",
    "    def get_action(self, s):\n",
    "        if np.random.uniform() < 1-eps:\n",
    "            return np.argmax(self.Q[s])\n",
    "        else:\n",
    "            return np.random.choice(list(range(len(self.Q[s]))))\n",
    "        \n",
    "    def update_Q(self):\n",
    "        earnings = []\n",
    "        if np.mean((self.Q_prev-self.Q)**2) > sys.float_info.epsilon**2 or self.counter <=max_num_iterations:\n",
    "            self.Q_prev=self.Q.copy()\n",
    "\n",
    "        s_prev=self.env.reset()\n",
    "        terminate = False\n",
    "        \n",
    "        while not terminate:\n",
    "            action=self.get_action(self.Q, s_prev)\n",
    "            s,reward,terminate=self.env.step(action)\n",
    "            \n",
    "            self.Q[s_prev][action] = self.Q[s_prev][action]+self.alpha*(reward+self.gamma*np.argmax(Q[s]) - self.Q[s_prev][action])\n",
    "            s_prev=s\n",
    "        earnings.append(reward) \n",
    "        return np.mean(earnings)\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bae48d7-5ce4-4b2f-85cc-527747b73183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4329aae5-aa14-43e3-8950-6e11b6338251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833a693a-10f6-4363-a8fd-b8a232f1621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_env = SexyEnvironment(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3b92b2-86a8-4abb-b871-18161f24b0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf7cfb-c1ec-4f34-9931-b51397fdbe02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1018bb24-b3ff-4c38-a76e-1e2e2e65df46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f0472f-8768-4c70-8089-c5f1bd1887a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26f0e39-0674-4c60-9758-d2c63854c6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b02c78-cb27-4691-89cf-412c10327290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11162334-2bfb-4fc9-9d0f-a716acb354d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
