{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dff80d3-fdfb-4f9f-bffe-1a2a2e6c9841",
   "metadata": {},
   "source": [
    "# RL and Advanced DL: Домашнее задание 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b574284-8495-4105-a0ae-ad43373a0678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "6bcbb6fc-2df2-4a63-9f7c-75d0dc4d7a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import sys\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as st\n",
    "import scipy.integrate as integrate\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn import linear_model\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import statsmodels.api as sm\n",
    "from matplotlib.colors import LogNorm\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from collections import namedtuple,deque\n",
    "from itertools import count\n",
    "from itertools import product\n",
    "import cProfile\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.autograd import Variable\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "palette = sns.color_palette()\n",
    "figsize = (15,8)\n",
    "legend_fontsize = 16\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif'})\n",
    "rc('text', usetex=True)\n",
    "# rc('text.latex',preamble=r'\\usepackage[utf8]{inputenc}')\n",
    "# rc('text.latex',preamble=r'\\usepackage[russian]{babel}')\n",
    "rc('figure', **{'dpi': 300})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6143170-a494-425b-9a9c-a93d62b456f8",
   "metadata": {},
   "source": [
    "## Классы для крестиков ноликов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c6c1016-1d1e-4f05-847b-361b26d84c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ROWS, N_COLS, N_WIN = 3, 3, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc2cad80-203e-40af-b0c3-2d2dbbf13601",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe(gym.Env):\n",
    "    def __init__(self, n_rows=N_ROWS, n_cols=N_COLS, n_win=N_WIN, clone=None):\n",
    "        if clone is not None:\n",
    "            self.n_rows, self.n_cols, self.n_win = clone.n_rows, clone.n_cols, clone.n_win\n",
    "            self.board = copy.deepcopy(clone.board)\n",
    "            self.curTurn = clone.curTurn\n",
    "            self.emptySpaces = None\n",
    "            self.boardHash = None\n",
    "        else:\n",
    "            self.n_rows = n_rows\n",
    "            self.n_cols = n_cols\n",
    "            self.n_win = n_win\n",
    "\n",
    "            self.reset()\n",
    "\n",
    "    def getEmptySpaces(self):\n",
    "        if self.emptySpaces is None:\n",
    "            res = np.where(self.board == 0)\n",
    "            self.emptySpaces = np.array([ (i, j) for i,j in zip(res[0], res[1]) ])\n",
    "        return self.emptySpaces\n",
    "\n",
    "    def makeMove(self, player, i, j):\n",
    "        self.board[i, j] = player\n",
    "        self.emptySpaces = None\n",
    "        self.boardHash = None\n",
    "\n",
    "    def getHash(self):\n",
    "        if self.boardHash is None:\n",
    "            self.boardHash = ''.join(['%s' % (x+1) for x in self.board.reshape(self.n_rows * self.n_cols)])\n",
    "        return self.boardHash\n",
    "\n",
    "    def isTerminal(self):\n",
    "        # проверим, не закончилась ли игра\n",
    "        cur_marks, cur_p = np.where(self.board == self.curTurn), self.curTurn\n",
    "        for i,j in zip(cur_marks[0], cur_marks[1]):\n",
    "            win = False\n",
    "            if i <= self.n_rows - self.n_win:\n",
    "                if np.all(self.board[i:i+self.n_win, j] == cur_p):\n",
    "                    win = True\n",
    "            if not win:\n",
    "                if j <= self.n_cols - self.n_win:\n",
    "                    if np.all(self.board[i,j:j+self.n_win] == cur_p):\n",
    "                        win = True\n",
    "            if not win:\n",
    "                if i <= self.n_rows - self.n_win and j <= self.n_cols - self.n_win:\n",
    "                    if np.all(np.array([ self.board[i+k,j+k] == cur_p for k in range(self.n_win) ])):\n",
    "                        win = True\n",
    "            if not win:\n",
    "                if i <= self.n_rows - self.n_win and j >= self.n_win-1:\n",
    "                    if np.all(np.array([ self.board[i+k,j-k] == cur_p for k in range(self.n_win) ])):\n",
    "                        win = True\n",
    "            if win:\n",
    "                self.gameOver = True\n",
    "                return self.curTurn\n",
    "\n",
    "        if len(self.getEmptySpaces()) == 0:\n",
    "            self.gameOver = True\n",
    "            return 0\n",
    "\n",
    "        self.gameOver = False\n",
    "        return None\n",
    "\n",
    "    def printBoard(self):\n",
    "        for i in range(0, self.n_rows):\n",
    "            print('----'*(self.n_cols)+'-')\n",
    "            out = '| '\n",
    "            for j in range(0, self.n_cols):\n",
    "                if self.board[i, j] == 1:\n",
    "                    token = 'x'\n",
    "                if self.board[i, j] == -1:\n",
    "                    token = 'o'\n",
    "                if self.board[i, j] == 0:\n",
    "                    token = ' '\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('----'*(self.n_cols)+'-')\n",
    "\n",
    "    def getState(self):\n",
    "        return (self.getHash(), self.getEmptySpaces(), self.curTurn)\n",
    "\n",
    "    def action_from_int(self, action_int):\n",
    "        return ( int(action_int / self.n_cols), int(action_int % self.n_cols))\n",
    "\n",
    "    def int_from_action(self, action):\n",
    "        return action[0] * self.n_cols + action[1]\n",
    "    \n",
    "    def step(self, action):\n",
    "        if self.board[action[0], action[1]] != 0:\n",
    "            return self.getState(), -10, True, {}\n",
    "        self.makeMove(self.curTurn, action[0], action[1])\n",
    "        reward = self.isTerminal()\n",
    "        self.curTurn = -self.curTurn\n",
    "        return self.getState(), 0 if reward is None else reward, reward is not None, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((self.n_rows, self.n_cols), dtype=int)\n",
    "        self.boardHash = None\n",
    "        self.gameOver = False\n",
    "        self.emptySpaces = None\n",
    "        self.curTurn = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e318d85c-6efc-473d-b5e5-09d96b2b079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_board(env, pi, showtext=True, verbose=True, fontq=20, fontx=60):\n",
    "    '''Рисуем доску с оценками из стратегии pi'''\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    X, Y = np.meshgrid(np.arange(0, env.n_rows), np.arange(0, env.n_rows))\n",
    "    Z = np.zeros((env.n_rows, env.n_cols)) + .01\n",
    "    s, actions = env.getHash(), env.getEmptySpaces()\n",
    "    if pi is not None and s in pi.Q:\n",
    "        for i, a in enumerate(actions):\n",
    "            Z[a[0], a[1]] = pi.Q[s][i]\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    surf = ax.imshow(Z, cmap=plt.get_cmap('Accent', 10), vmin=-1, vmax=1)\n",
    "    if showtext:\n",
    "        for i,a in enumerate(actions):\n",
    "            if pi is not None and s in pi.Q:\n",
    "                ax.text( a[1] , a[0] , \"%.3f\" % pi.Q[s][i], fontsize=fontq, horizontalalignment='center', verticalalignment='center', color=\"w\" )\n",
    "    for i in range(env.n_rows):\n",
    "        for j in range(env.n_cols):\n",
    "            if env.board[i, j] == -1:\n",
    "                ax.text(j, i, \"O\", fontsize=fontx, horizontalalignment='center', verticalalignment='center', color=\"w\" )\n",
    "            if env.board[i, j] == 1:\n",
    "                ax.text(j, i, \"X\", fontsize=fontx, horizontalalignment='center', verticalalignment='center', color=\"w\" )\n",
    "#     cbar = plt.colorbar(surf, ticks=[0, 1])\n",
    "    ax.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "def get_and_print_move(env, pi, s, actions, random=False, verbose=True, fontq=20, fontx=60):\n",
    "    '''Делаем ход, рисуем доску'''\n",
    "    plot_board(env, pi, fontq=fontq, fontx=fontx)\n",
    "    if verbose and (pi is not None):\n",
    "        if s in pi.Q:\n",
    "            for i,a in enumerate(actions):\n",
    "                print(i, a, pi.Q[s][i])\n",
    "        else:\n",
    "            print(\"Стратегия не знает, что делать...\")\n",
    "    if random:\n",
    "        return np.random.randint(len(actions))\n",
    "    else:\n",
    "        return pi.getActionGreedy(s, len(actions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60cab69-cc35-476f-9803-1d1b061604c9",
   "metadata": {},
   "source": [
    "\n",
    "# Табличный Q-learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a113379-663b-4c3e-8738-7458c6a44989",
   "metadata": {},
   "source": [
    "## Идея: сделаем два агента, которые будут играть друг против друга по своим табличным функциям \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537b981b-d0f3-4f37-8981-db44215a93f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "814ea356-c546-403f-bec6-625471a9f62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SexyEnvironment():\n",
    "    def __init__(self,base_env):\n",
    "        \n",
    "        self.env = base_env\n",
    "        self.env.reset()\n",
    "        \n",
    "        self.action_space_dim = len(self.env.getState()[1])\n",
    "        self.state_space_dim = 3** len(self.env.getState()[0])\n",
    "        self.state_spaces = len(self.env.getState()[0])\n",
    "        \n",
    "        # self.state_to_int={v:k for k,v in enumerate(product('012', repeat=self.state_space_dim))}\n",
    "        # self.state = self._get_state()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.env.reset()\n",
    "        return tuple(map(int,self.env.getState()[0]))\n",
    "    @property\n",
    "    def state(self):\n",
    "        return tuple(map(int,self.env.getState()[0]))\n",
    "        \n",
    "    def step(self,action):\n",
    "        env_output = self.env.step(self.env.action_from_int(action))\n",
    "        state= tuple(map(int,env_output[0][0]))\n",
    "        reward = env_output[1]\n",
    "        terminated = env_output[2]\n",
    "        \n",
    "        return state,reward,terminated\n",
    "    def sample(self):\n",
    "        return np.random.choice(list(range(self.action_space_dim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0e7e2d20-a525-4b0c-83d9-e8f7c5c13e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableQlearning():\n",
    "    def __init__(self,action_space_dim,state_spaces,alpha=0.1,gamma=0.1):\n",
    "        self.Q = np.random.uniform(size=(tuple([3 for _ in range(state_spaces)])+(action_space_dim,)))\n",
    "        self.max_learning_iterations = 10_000\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        self.epsilon = 0.5\n",
    "        self.epsilon_discount_factor = 0.99\n",
    "        self.epsilon_decrease_every = 10**4\n",
    "        self.counter = 1\n",
    "        self.Q_prev = None\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_greedy_action(self, s):\n",
    "        \n",
    "        if np.random.uniform() < 1-self.epsilon:\n",
    "            return np.argmax(self.Q[s])\n",
    "        else:\n",
    "            return np.random.choice(list(range(len(self.Q[s]))))\n",
    "        \n",
    "    def step(self,s_prev,action,reward,s):\n",
    "        if self.counter % self.epsilon_decrease_every  ==0:\n",
    "            self.epsilon = self.epsilon_discount_factor*self.epsilon\n",
    "       \n",
    "        self.Q[s_prev][action] = self.Q[s_prev][action]+self.alpha*(reward+self.gamma*np.argmax(self.Q[s]) - self.Q[s_prev][action])\n",
    "      \n",
    "        self.counter+=1\n",
    "    \n",
    "    \n",
    "    def get_optimal_action(self,s):\n",
    "        return np.argmax(self.Q[s])\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "60afe120-6eea-450e-8158-bd35db605f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_learn(agent,env,num_games=10):\n",
    "    rewards=[]\n",
    "    for game_num in range(num_games):\n",
    "        s_prev = env.reset()\n",
    "        \n",
    "        terminate=False\n",
    "    \n",
    "        \n",
    "        while not terminate:\n",
    "            action = agent.get_greedy_action(s_prev)\n",
    "            s,raw_reward,terminate = env.step(action)\n",
    "            \n",
    "            if raw_reward ==-1:\n",
    "                reward=1\n",
    "            else:\n",
    "                reward = raw_reward\n",
    "                \n",
    "            agent.step(s_prev,action,reward,s)\n",
    "            s_prev=s\n",
    "            \n",
    "            \n",
    "        rewards.append(raw_reward)\n",
    "            \n",
    "       \n",
    "        if game_num % 10000==0:\n",
    "            \n",
    "            print(f'Game #{game_num}\\t Reward {np.mean(rewards[-100:]):.3f}\\tEps{agent.epsilon}')\n",
    "            \n",
    "    return rewards\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd81ad24-7355-49dc-bce9-2cbb05577468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "7e1501e0-3d2a-4388-8a8a-8ac719739024",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_env = TicTacToe(n_rows=3, n_cols=3, n_win=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "77cea89f-02e6-460d-9ec6-c38cc92aeffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=SexyEnvironment(other_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "6bae48d7-5ce4-4b2f-85cc-527747b73183",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = TableQlearning(action_space_dim=env.action_space_dim,state_spaces=env.state_spaces)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ff3b92b2-86a8-4abb-b871-18161f24b0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game #0\t Reward -10.000\tEps0.5\n",
      "Game #10000\t Reward -8.060\tEps0.47549502494999996\n",
      "Game #20000\t Reward -6.250\tEps0.45219103750440215\n",
      "Game #30000\t Reward -5.730\tEps0.43002917732064416\n",
      "Game #40000\t Reward -3.980\tEps0.4089534687986153\n",
      "Game #50000\t Reward -4.480\tEps0.38502157290257755\n",
      "Game #60000\t Reward -4.730\tEps0.3661516848271987\n",
      "Game #70000\t Reward -4.400\tEps0.34820660902478673\n",
      "Game #80000\t Reward -4.290\tEps0.33114102049199173\n",
      "Game #90000\t Reward -3.670\tEps0.31491181560161613\n",
      "Game #100000\t Reward -4.330\tEps0.2964832232007497\n",
      "Game #110000\t Reward -3.720\tEps0.2819525952261938\n",
      "Game #120000\t Reward -3.390\tEps0.2681341126035925\n",
      "Game #130000\t Reward -3.340\tEps0.2524429443935348\n",
      "Game #140000\t Reward -4.100\tEps0.2400707282857106\n",
      "Game #150000\t Reward -2.600\tEps0.22830487387195728\n",
      "Game #160000\t Reward -1.510\tEps0.21711566339590585\n",
      "Game #170000\t Reward -2.810\tEps0.20441008721127468\n",
      "Game #180000\t Reward -2.450\tEps0.19439195903711348\n",
      "Game #190000\t Reward -2.330\tEps0.18486481882486328\n",
      "Game #200000\t Reward -2.740\tEps0.17580460327901115\n",
      "Game #210000\t Reward -1.400\tEps0.16551654416050693\n",
      "Game #220000\t Reward -1.360\tEps0.15740458659047601\n",
      "Game #230000\t Reward -1.940\tEps0.14969019565616562\n",
      "Game #240000\t Reward -0.850\tEps0.1423538866365977\n",
      "Game #250000\t Reward -1.060\tEps0.135377129755997\n",
      "Game #260000\t Reward -1.100\tEps0.1274548803481546\n",
      "Game #270000\t Reward -0.790\tEps0.12120832302229008\n",
      "Game #280000\t Reward -1.300\tEps0.11526790915926297\n",
      "Game #290000\t Reward -0.240\tEps0.10961863468323617\n",
      "Game #300000\t Reward -0.530\tEps0.10424623086738063\n",
      "Game #310000\t Reward -0.070\tEps0.09814575701151265\n",
      "Game #320000\t Reward -0.310\tEps0.09333563835785168\n",
      "Game #330000\t Reward -0.310\tEps0.08876126337938173\n",
      "Game #340000\t Reward 0.150\tEps0.08441107829034528\n",
      "Game #350000\t Reward 0.280\tEps0.08027409555544825\n",
      "Game #360000\t Reward 0.060\tEps0.0763398661379531\n",
      "Game #370000\t Reward -0.140\tEps0.07259845310789134\n",
      "Game #380000\t Reward 0.390\tEps0.06835000247829902\n",
      "Game #390000\t Reward 0.430\tEps0.06500017226750271\n",
      "Game #400000\t Reward 0.180\tEps0.061814517068181\n",
      "Game #410000\t Reward 0.430\tEps0.05878499067121386\n",
      "Game #420000\t Reward -0.010\tEps0.0559039412117887\n",
      "Game #430000\t Reward 0.170\tEps0.053164091842605614\n",
      "Game #440000\t Reward 0.480\tEps0.05055852235428769\n",
      "Game #450000\t Reward 0.460\tEps0.048080651696574314\n",
      "Game #460000\t Reward 0.040\tEps0.04572422135614973\n",
      "Game #470000\t Reward 0.500\tEps0.04348327954912347\n",
      "Game #480000\t Reward 0.410\tEps0.040938644526354206\n",
      "Game #490000\t Reward 0.450\tEps0.03893224360095594\n",
      "Game #500000\t Reward 0.760\tEps0.03702417628479206\n",
      "Game #510000\t Reward 0.410\tEps0.03520962325258079\n",
      "Game #520000\t Reward 0.190\tEps0.033484001373932\n",
      "Game #530000\t Reward 0.390\tEps0.03184295213744726\n",
      "Game #540000\t Reward 0.450\tEps0.03028233064215428\n",
      "Game #550000\t Reward 0.870\tEps0.028798195128470597\n",
      "Game #560000\t Reward 0.630\tEps0.02738679702225419\n",
      "Game #570000\t Reward 0.760\tEps0.026044571466794682\n",
      "Game #580000\t Reward 0.650\tEps0.02476812831883119\n",
      "Game #590000\t Reward 0.830\tEps0.023554243585854874\n",
      "Game #600000\t Reward 0.960\tEps0.02239985128306888\n",
      "Game #610000\t Reward 0.760\tEps0.02130203568943825\n",
      "Game #620000\t Reward 0.890\tEps0.020258023983270458\n",
      "Game #630000\t Reward 0.560\tEps0.019265179238725765\n",
      "Game #640000\t Reward 0.780\tEps0.018320993765568255\n",
      "Game #650000\t Reward 0.830\tEps0.01742308277533534\n",
      "Game #660000\t Reward 0.540\tEps0.016569178357927986\n",
      "Game #670000\t Reward 0.670\tEps0.015599552515873855\n",
      "Game #680000\t Reward 0.650\tEps0.014835019225488548\n",
      "Game #690000\t Reward 0.980\tEps0.014107955673514812\n",
      "Game #700000\t Reward 0.780\tEps0.013416525469942838\n",
      "Game #710000\t Reward 0.980\tEps0.012758982226145561\n",
      "Game #720000\t Reward 0.870\tEps0.012133665143915378\n",
      "Game #730000\t Reward 0.870\tEps0.011538994820681976\n",
      "Game #740000\t Reward 0.850\tEps0.010973469260316195\n",
      "Game #750000\t Reward 0.890\tEps0.010435660079444213\n",
      "Game #760000\t Reward 1.000\tEps0.00992420889969009\n",
      "Game #770000\t Reward 0.670\tEps0.009437823916734301\n",
      "Game #780000\t Reward 0.760\tEps0.008975276637522567\n",
      "Game #790000\t Reward 0.890\tEps0.008535398777383891\n",
      "Game #800000\t Reward 0.780\tEps0.008117079309220706\n",
      "Game #810000\t Reward 0.780\tEps0.0077192616573180575\n",
      "Game #820000\t Reward 1.000\tEps0.007340941028684056\n",
      "Game #830000\t Reward 1.000\tEps0.006981161875181207\n",
      "Game #840000\t Reward 0.890\tEps0.006639015480038553\n",
      "Game #850000\t Reward 1.000\tEps0.006313637662648735\n",
      "Game #860000\t Reward 1.000\tEps0.00600420659585284\n",
      "Game #870000\t Reward 0.890\tEps0.005709940730200002\n",
      "Game #880000\t Reward 0.780\tEps0.005430096819938943\n",
      "Game #890000\t Reward 0.980\tEps0.0051639680457555666\n",
      "Game #900000\t Reward 1.000\tEps0.004910882229515091\n",
      "Game #910000\t Reward 0.890\tEps0.004670200136499578\n",
      "Game #920000\t Reward 1.000\tEps0.00444131386085272\n",
      "Game #930000\t Reward 0.890\tEps0.00422364529015389\n",
      "Game #940000\t Reward 1.000\tEps0.004016644645243348\n",
      "Game #950000\t Reward 1.000\tEps0.0038197890916105387\n",
      "Game #960000\t Reward 1.000\tEps0.0036325814188381818\n",
      "Game #970000\t Reward 1.000\tEps0.0034545487847667355\n",
      "Game #980000\t Reward 1.000\tEps0.0032852415212073025\n",
      "Game #990000\t Reward 1.000\tEps0.0031242319981864843\n"
     ]
    }
   ],
   "source": [
    "rewards = Q_learn(agent,env,num_games=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "33b96728-7ea8-4292-8aa6-487d13a7278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a70e7883-5cbc-45dd-8607-66b46c084d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to process string with tex because latex could not be found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36m_run_checked_subprocess\u001b[0;34m(self, command, tex, cwd)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             report = subprocess.check_output(\n\u001b[0m\u001b[1;32m    234\u001b[0m                 \u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcwd\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexcache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.9/Frameworks/Python.framework/Versions/3.9/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0m\u001b[1;32m    425\u001b[0m                **kwargs).stdout\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.9/Frameworks/Python.framework/Versions/3.9/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.9/Frameworks/Python.framework/Versions/3.9/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.9/3.9.9/Frameworks/Python.framework/Versions/3.9/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1820\u001b[0m                         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1821\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1822\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'latex'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2288\u001b[0m                 )\n\u001b[1;32m   2289\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_draw_disabled\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnullcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2290\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rasterizing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2803\u001b[0;31m             mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   2804\u001b[0m                 renderer, self, artists, self.suppressComposite)\n\u001b[1;32m   2805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3044\u001b[0m                 \u001b[0martists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3046\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_title_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxison\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_update_title_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2984\u001b[0m                 if (ax.xaxis.get_ticks_position() in ['top', 'unknown']\n\u001b[1;32m   2985\u001b[0m                         or ax.xaxis.get_label_position() == 'top'):\n\u001b[0;32m-> 2986\u001b[0;31m                     \u001b[0mbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2987\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m                     \u001b[0mbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_window_extent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, for_layout_only)\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_label_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;31m# go back to just this axis's tick labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_label_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2081\u001b[0m         \u001b[0;31m# get bounding boxes for this axis and any siblings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m         \u001b[0;31m# that have been set by `fig.align_xlabels()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2083\u001b[0;31m         \u001b[0mbboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbboxes2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick_boxes_siblings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2085\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_boxes_siblings\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1879\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{axis_name}axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m             \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1881\u001b[0;31m             \u001b[0mtlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtlb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick_bboxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticks_to_draw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1882\u001b[0m             \u001b[0mbboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m             \u001b[0mbboxes2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_bboxes\u001b[0;34m(self, ticks, renderer)\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_tick_bboxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0m\u001b[1;32m   1086\u001b[0m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[1;32m   1087\u001b[0m                 [tick.label2.get_window_extent(renderer)\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_tick_bboxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0m\u001b[1;32m   1086\u001b[0m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[1;32m   1087\u001b[0m                 [tick.label2.get_window_extent(renderer)\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m             \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36m_get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;31m# Full vertical extent of font, including ascenders and descenders:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         _, lp_h, lp_d = renderer.get_text_width_height_descent(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0;34m\"lp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fontproperties\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             ismath=\"TeX\" if self.get_usetex() else False)\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[0;34m(self, s, prop, ismath)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mtexmanager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_texmanager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mfontsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_size_in_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             w, h, d = texmanager.get_text_width_height_descent(\n\u001b[0m\u001b[1;32m    260\u001b[0m                 s, fontsize, renderer=self)\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[0;34m(self, tex, fontsize, renderer)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mdvifile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dvi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0mdpi_fraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints_to_pixels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrenderer\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdviread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDvi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdvifile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m72\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdpi_fraction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdvi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36mmake_dvi\u001b[0;34m(self, tex, fontsize)\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;31m# not support.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mTemporaryDirectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdvifile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtmpdir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 self._run_checked_subprocess(\n\u001b[0m\u001b[1;32m    272\u001b[0m                     [\"latex\", \"-interaction=nonstopmode\", \"--halt-on-error\",\n\u001b[1;32m    273\u001b[0m                      f\"../{texfile.name}\"], tex, cwd=tmpdir)\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36m_run_checked_subprocess\u001b[0;34m(self, command, tex, cwd)\u001b[0m\n\u001b[1;32m    235\u001b[0m                 stderr=subprocess.STDOUT)\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    238\u001b[0m                 \u001b[0;34m'Failed to process string with tex because {} could not be '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 'found'.format(command[0])) from exc\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to process string with tex because latex could not be found"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(rewards).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c7cf7cfb-c1ec-4f34-9931-b51397fdbe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5dc69d73-6bde-4824-9611-f69b6f737588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "env.env.printBoard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "32a9f88e-1ff7-4e42-ad3b-ee6d409016f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s= env.reset()\n",
    "terminate=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "ee66fc75-0d4c-49d4-9333-bdbe26f86ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 2, 0, 0, 2, 0, 1, 2)\n",
      "(1, 1, 2, 0, 0, 2, 0, 1, 2) (1, 2) -10\n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "| o | o | x | \n",
      "-------------\n",
      "| o |   | x | \n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(s)        \n",
    "action = agent.get_optimal_action(s)\n",
    "\n",
    "\n",
    "s,raw_reward,terminate = env.step(action)\n",
    "\n",
    "print(s,env.env.action_from_int(action),raw_reward)\n",
    "\n",
    "env.env.printBoard()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1287,
   "id": "1018bb24-b3ff-4c38-a76e-1e2e2e65df46",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TableQlearningAgent' object has no attribute 'one_step'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_w/53z1qlws0f5fr7nqtd4byw_r0000gn/T/ipykernel_9119/4045294322.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent_cross\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'TableQlearningAgent' object has no attribute 'one_step'"
     ]
    }
   ],
   "source": [
    "agent_cross.one_step(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "id": "26f0472f-8768-4c70-8089-c5f1bd1887a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "|   |   | o | \n",
      "-------------\n",
      "| x |   | x | \n",
      "-------------\n",
      "| x | o |   | \n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "env.env.printBoard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "id": "d26f0e39-0674-4c60-9758-d2c63854c6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, False)"
      ]
     },
     "execution_count": 1039,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_zeros.one_step(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "id": "a8b02c78-cb27-4691-89cf-412c10327290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "|   |   | o | \n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "| x | o |   | \n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "env.env.printBoard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0f93be-0dbb-424f-a102-f0dbbdd65cbc",
   "metadata": {},
   "source": [
    "# Часть 2. Нейронные сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "17f85be8-01cf-4bb6-8ad3-897c82644487",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        self.steps = 0 # Do not change\n",
    "         \n",
    "        self.replay_buffer=deque(maxlen=MEMORY_SIZE)\n",
    "\n",
    "    \n",
    "        \n",
    "        self.policy_network = nn.Sequential( \n",
    "                                        nn.Linear(state_dim,64),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(64,64),\n",
    "                                        nn.ReLU(),   \n",
    "                                        nn.Linear(64,action_dim),\n",
    "                                        ) \n",
    "        \n",
    "        \n",
    "        self.target_network=copy.deepcopy(self.policy_network)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.policy_network.parameters(),lr=LEARNING_RATE)\n",
    "#\n",
    "        \n",
    "        \n",
    "    def consume_transition(self, transition):\n",
    "        self.replay_buffer.append((torch.tensor(transition[0],dtype=torch.float32),\n",
    "                                  torch.tensor([transition[1]]),\n",
    "                                  torch.tensor(transition[2],dtype=torch.float32),\n",
    "                                  torch.tensor([transition[3]]),\n",
    "                                  torch.tensor([transition[4]]))\n",
    "        )\n",
    "       \n",
    "    \n",
    "\n",
    "    def sample_batch(self):        \n",
    "        batch = random.sample(self.replay_buffer,BATCH_SIZE)\n",
    "        \n",
    "        return Transition(*zip(*batch))\n",
    "        \n",
    "    def train_step(self, batch):\n",
    "        self.policy_network.train()\n",
    "        self.target_network.eval()\n",
    "        \n",
    "        \n",
    "        state_batch = torch.stack(batch.state)\n",
    "        action_batch = torch.stack(batch.action)\n",
    "        reward_batch = torch.stack(batch.reward)\n",
    "        next_states = torch.stack(batch.next_state)\n",
    "        dones = torch.stack(batch.done)*1\n",
    "\n",
    "        \n",
    "        q_targets_next = self.target_network(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        q_targets = reward_batch + GAMMA * q_targets_next * (1 - dones)\n",
    "        q_expected = self.policy_network(state_batch).gather(1, action_batch)\n",
    "        \n",
    "        loss = F.smooth_l1_loss(q_expected.float(), q_targets.float())\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in self.policy_network.parameters():\n",
    "\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        self.optimizer.step()\n",
    "#\n",
    "        \n",
    "\n",
    "        \n",
    "    def update_target_network(self):\n",
    "        # Update weights of a target Q-network here. You may use copy.deepcopy to do this or \n",
    "        # assign a values of network parameters via PyTorch methods.\n",
    "        for target_param, local_param in zip(self.target_network.parameters(), self.policy_network.parameters()):\n",
    "            target_param.data.copy_(TAU*local_param.data + (1.0-TAU)*target_param.data)\n",
    "        \n",
    "\n",
    "    def act(self, state, target=False):\n",
    "        # Compute an action. Do not forget to turn state to a Tensor and then turn an action to a numpy array.\n",
    "        self.target_network.eval()\n",
    "        self.policy_network.eval()\n",
    "        \n",
    "        action = torch.argmax(dqn.policy_network(torch.tensor(state,dtype=torch.float32))).item()\n",
    "        return action\n",
    "\n",
    "    def update(self, transition):\n",
    "        \n",
    "        self.consume_transition(transition)\n",
    "        if self.steps % STEPS_PER_UPDATE == 0:\n",
    "            batch = self.sample_batch()\n",
    "            self.train_step(batch)\n",
    "        if self.steps % STEPS_PER_TARGET_UPDATE == 0:\n",
    "            self.update_target_network()\n",
    "        self.steps += 1\n",
    "\n",
    "    # def save(self,name=''):\n",
    "    #     torch.save(self.policy_network.state_dict(), name+\"agent.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "92db5ac0-bb50-4197-8471-863ac64d5865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_policy(agent, episodes=5):\n",
    "    \n",
    "    \n",
    "    returns = []\n",
    "    total_reward=0\n",
    "    for _ in range(episodes):\n",
    "        done = False\n",
    "        state = env.reset()\n",
    "        \n",
    "        \n",
    "        while not done:\n",
    "            state, reward, done = env.step(agent.act(state))\n",
    "            total_reward += reward\n",
    "        returns.append(total_reward)\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "2bf338c7-544f-4e39-947a-6a5f9055451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99\n",
    "INITIAL_STEPS = 1024\n",
    "TRANSITIONS = 500000\n",
    "STEPS_PER_UPDATE = 2\n",
    "STEPS_PER_TARGET_UPDATE = STEPS_PER_UPDATE * 1\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 5e-4\n",
    "MEMORY_SIZE=INITIAL_STEPS\n",
    "TAU=1e-3\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward','done'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "6d36d814-3f66-4e80-8db4-b4491100780d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -1.2345,  -9.3047, -10.1442,  -0.7584,  -2.6587,  -6.5407,  -6.5867,\n",
       "         -4.4503,  -9.3494], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.policy_network(torch.tensor(state).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "6b28d191-162c-4e86-8c6f-705c3429c854",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SexyEnvironment(other_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "6f060353-47e9-4ded-9d35-fc8451665754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "aa7b4c2c-5c0e-4679-9429-6d8492d5d404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1, Reward mean: -55.0, Reward std: 28.722813232690143\n",
      "Step: 1001, Reward mean: -55.0, Reward std: 28.722813232690143\n",
      "Step: 2001, Reward mean: -55.0, Reward std: 28.722813232690143\n",
      "Step: 3001, Reward mean: -55.0, Reward std: 28.722813232690143\n",
      "Step: 4001, Reward mean: -55.0, Reward std: 28.722813232690143\n",
      "Step: 5001, Reward mean: -55.0, Reward std: 28.722813232690143\n",
      "Step: 6001, Reward mean: -55.0, Reward std: 28.722813232690143\n",
      "Step: 7001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 8001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 9001, Reward mean: -55.0, Reward std: 28.722813232690143\n",
      "Step: 10001, Reward mean: -55.0, Reward std: 28.722813232690143\n",
      "Step: 11001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 12001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 13001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 14001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 15001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 16001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 17001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 18001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 19001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 20001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 21001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 22001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 23001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 24001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 25001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 26001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 27001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 28001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 29001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 30001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 31001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 32001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 33001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 34001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 35001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 36001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 37001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 38001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 39001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 40001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 41001, Reward mean: -5.5, Reward std: 2.8722813232690143\n",
      "Step: 42001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 43001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 44001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 45001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 46001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 47001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 48001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 49001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 50001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 51001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 52001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 53001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 54001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 55001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 56001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 57001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 58001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 59001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 60001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 61001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 62001, Reward mean: 5.5, Reward std: 2.8722813232690143\n",
      "Step: 63001, Reward mean: 5.5, Reward std: 2.8722813232690143\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_w/53z1qlws0f5fr7nqtd4byw_r0000gn/T/ipykernel_16078/2494964909.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/_w/53z1qlws0f5fr7nqtd4byw_r0000gn/T/ipykernel_16078/1042798097.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, transition)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mSTEPS_PER_UPDATE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mSTEPS_PER_TARGET_UPDATE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_target_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/_w/53z1qlws0f5fr7nqtd4byw_r0000gn/T/ipykernel_16078/1042798097.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mparameters\u001b[0;34m(self, recurse)\u001b[0m\n\u001b[1;32m   1518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m         \"\"\"\n\u001b[0;32m-> 1520\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_parameters\u001b[0;34m(self, prefix, recurse)\u001b[0m\n\u001b[1;32m   1544\u001b[0m             \u001b[0;32mlambda\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m             prefix=prefix, recurse=recurse)\n\u001b[0;32m-> 1546\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1547\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_named_members\u001b[0;34m(self, get_members_fn, prefix, recurse)\u001b[0m\n\u001b[1;32m   1491\u001b[0m             \u001b[0mmembers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_members_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1493\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1494\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.global_env/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__hash__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dqn = DQN(state_dim=env.state_spaces, action_dim=env.action_space_dim)\n",
    "\n",
    "state = env.reset()\n",
    "EPS_DECAY=0.9\n",
    "EPS_END=0.05\n",
    "EPS_START=1\n",
    "eps = EPS_START\n",
    "max_reward = float('-inf')\n",
    "\n",
    "for _ in range(INITIAL_STEPS):\n",
    "    action = dqn.act(state)\n",
    "\n",
    "    next_state, reward, done = env.step(action)\n",
    "    dqn.consume_transition((state, action, next_state, reward, done))\n",
    "\n",
    "    state = next_state if not done else env.reset()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(TRANSITIONS):\n",
    "   \n",
    "    if random.random() < eps:\n",
    "        action = env.sample()\n",
    "    else:\n",
    "        action = dqn.act(state)\n",
    "\n",
    "    eps = max(EPS_END, EPS_DECAY*eps)\n",
    "\n",
    "    next_state, reward, done = env.step(action)\n",
    "    dqn.update((state, action, next_state, reward, done))\n",
    "\n",
    "    state = next_state if not done else env.reset()\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        rewards = evaluate_policy(dqn,10)\n",
    "        \n",
    "        print(f\"Step: {i+1}, Reward mean: {np.mean(rewards)}, Reward std: {np.std(rewards)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e921c9-17c3-42fc-96a7-61ef36b53a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f364d37-3ca3-445f-b0c5-53d307d24fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "285179ea-1299-4e50-b87c-39db060dd4c3",
   "metadata": {},
   "source": [
    "# TODO\n",
    "state spaces - state dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6314ab-30a9-48ab-851d-5c9f53b5134f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f19457-77de-46f9-ba27-d4010d93288e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b874f9-7d00-43de-b666-2e0b5291cb5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
